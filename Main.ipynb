{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f227443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "#import SimpleITK as sitk\n",
    "from torch import optim\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import natsort\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from Data_Loader import Images_Dataset, Images_Dataset_folder\n",
    "import torchsummary\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#from tensorboardX import SummaryWriter\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "from Models import Unet_dict, NestedUNet, U_Net, R2U_Net, AttU_Net, R2AttU_Net\n",
    "from losses import calc_loss, dice_loss, threshold_predictions_v,threshold_predictions_p\n",
    "from ploting import plot_kernels, LayerActivations, input_images, plot_grad_flow\n",
    "from Metrics import dice_coeff, accuracy_score\n",
    "import time\n",
    "#from ploting import VisdomLinePlotter\n",
    "#from visdom import Visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a136463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Training on GPU\n",
      "batch_size = 4\n",
      "epoch = 10\n",
      "random_seed = 53\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#Checking if GPU is used\n",
    "#######################################################\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available. Training on CPU')\n",
    "else:\n",
    "    print('CUDA is available. Training on GPU')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
    "\n",
    "#######################################################\n",
    "#Setting the basic paramters of the model\n",
    "#######################################################\n",
    "\n",
    "batch_size = 4\n",
    "print('batch_size = ' + str(batch_size))\n",
    "\n",
    "valid_size = 0.15\n",
    "\n",
    "epoch = 10\n",
    "print('epoch = ' + str(epoch))\n",
    "\n",
    "random_seed = random.randint(1, 100)\n",
    "print('random_seed = ' + str(random_seed))\n",
    "\n",
    "shuffle = True\n",
    "valid_loss_min = np.Inf\n",
    "num_workers = 0\n",
    "lossT = []\n",
    "lossL = []\n",
    "lossL.append(np.inf)\n",
    "lossT.append(np.inf)\n",
    "epoch_valid = epoch-2\n",
    "n_iter = 1\n",
    "i_valid = 0\n",
    "\n",
    "pin_memory = False\n",
    "if train_on_gpu:\n",
    "    pin_memory = True\n",
    "\n",
    "#plotter = VisdomLinePlotter(env_name='Tutorial Plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882ce17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "U_Net(\n",
       "  (Maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv1): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up5): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up4): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up3): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up2): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################\n",
    "#Setting up the model\n",
    "#######################################################\n",
    "\n",
    "model_Inputs = [U_Net, R2U_Net, AttU_Net, R2AttU_Net, NestedUNet]\n",
    "\n",
    "\n",
    "def model_unet(model_input, in_channel=1, out_channel=1):\n",
    "    model_test = model_input(in_channel, out_channel)\n",
    "    return model_test\n",
    "\n",
    "#passsing this string so that if it's AttU_Net or R2ATTU_Net it doesn't throw an error at torchSummary\n",
    "\n",
    "# Using U-Net == model_Input[0]\n",
    "model_test = model_unet(model_Inputs[0], 1, 1)\n",
    "\n",
    "model_test.to(device)\n",
    "\n",
    "#######################################################\n",
    "#Getting the Summary of Model\n",
    "#######################################################\n",
    "#torchsummary.summary(model_test, input_size=(3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86cd5a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Data_Loader.Images_Dataset_folder at 0x1c996e000c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################\n",
    "#Passing the Dataset of Images and Labels\n",
    "#######################################################\n",
    "\n",
    "t_data = 'C:/Users/sli248/ZReconstruction/DeepLearning/Dataset/20230302Dataset/train/input/'\n",
    "l_data = 'C:/Users/sli248/ZReconstruction/DeepLearning/Dataset/20230302Dataset/train/label/'\n",
    "test_image = 'C:/Users/sli248/ZReconstruction/DeepLearning/Dataset/20230302Dataset/val/input/female_2_108.png'\n",
    "test_label = 'C:/Users/sli248/ZReconstruction/DeepLearning/Dataset/20230302Dataset/val/label/female_2_108.png'\n",
    "test_folderP = 'C:/Users/sli248/ZReconstruction/DeepLearning/Dataset/20230302Dataset/val/input/'\n",
    "test_folderL = 'C:/Users/sli248/ZReconstruction/DeepLearning/Dataset/20230302Dataset/val/label/'\n",
    "\n",
    "Training_Data = Images_Dataset_folder(t_data,\n",
    "                                      l_data)\n",
    "Training_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b09ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#Giving a transformation for input data\n",
    "#######################################################\n",
    "\n",
    "data_transform = torchvision.transforms.Compose([\n",
    "          #  torchvision.transforms.Resize((128,128)),\n",
    "         #   torchvision.transforms.CenterCrop(96),\n",
    "            torchvision.transforms.ToTensor()#,\n",
    "            #torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "#######################################################\n",
    "#Trainging Validation Split\n",
    "#######################################################\n",
    "\n",
    "num_train = len(Training_Data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "if shuffle:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(Training_Data, batch_size=batch_size, sampler=train_sampler,\n",
    "                                           num_workers=num_workers, pin_memory=pin_memory,)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(Training_Data, batch_size=batch_size, sampler=valid_sampler,\n",
    "                                           num_workers=num_workers, pin_memory=pin_memory,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e792a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#Using Adam as Optimizer\n",
    "#######################################################\n",
    "\n",
    "initial_lr = 0.001\n",
    "opt = torch.optim.Adam(model_test.parameters(), lr=initial_lr) # try SGD\n",
    "#opt = optim.SGD(model_test.parameters(), lr = initial_lr, momentum=0.99)\n",
    "\n",
    "MAX_STEP = int(1e10)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, MAX_STEP, eta_min=1e-5)\n",
    "#scheduler = optim.lr_scheduler.CosineAnnealingLr(opt, epoch, 1)\n",
    "\n",
    "#######################################################\n",
    "#Writing the params to tensorboard\n",
    "#######################################################\n",
    "\n",
    "#writer1 = SummaryWriter()\n",
    "#dummy_inp = torch.randn(1, 3, 128, 128)\n",
    "#model_test.to('cpu')\n",
    "#writer1.add_graph(model_test, model_test(torch.randn(3, 3, 128, 128, requires_grad=True)))\n",
    "#model_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "750f0ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the main directory './model' \n",
      "Successfully created the prediction directory './model/pred' of dice loss\n",
      "Successfully created the model directory './model/Unet_D_10_4' \n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#Creating a Folder for every data of the program\n",
    "#######################################################\n",
    "\n",
    "New_folder = './model'\n",
    "\n",
    "if os.path.exists(New_folder) and os.path.isdir(New_folder):\n",
    "    shutil.rmtree(New_folder)\n",
    "\n",
    "try:\n",
    "    os.mkdir(New_folder)\n",
    "except OSError:\n",
    "    print(\"Creation of the main directory '%s' failed \" % New_folder)\n",
    "else:\n",
    "    print(\"Successfully created the main directory '%s' \" % New_folder)\n",
    "\n",
    "#######################################################\n",
    "#Setting the folder of saving the predictions\n",
    "#######################################################\n",
    "\n",
    "read_pred = './model/pred'\n",
    "\n",
    "#######################################################\n",
    "#Checking if prediction folder exixts\n",
    "#######################################################\n",
    "\n",
    "if os.path.exists(read_pred) and os.path.isdir(read_pred):\n",
    "    shutil.rmtree(read_pred)\n",
    "\n",
    "try:\n",
    "    os.mkdir(read_pred)\n",
    "except OSError:\n",
    "    print(\"Creation of the prediction directory '%s' failed of dice loss\" % read_pred)\n",
    "else:\n",
    "    print(\"Successfully created the prediction directory '%s' of dice loss\" % read_pred)\n",
    "\n",
    "#######################################################\n",
    "#checking if the model exists and if true then delete\n",
    "#######################################################\n",
    "\n",
    "read_model_path = './model/Unet_D_' + str(epoch) + '_' + str(batch_size)\n",
    "\n",
    "if os.path.exists(read_model_path) and os.path.isdir(read_model_path):\n",
    "    shutil.rmtree(read_model_path)\n",
    "    print('Model folder there, so deleted for newer one')\n",
    "\n",
    "try:\n",
    "    os.mkdir(read_model_path)\n",
    "except OSError:\n",
    "    print(\"Creation of the model directory '%s' failed\" % read_model_path)\n",
    "else:\n",
    "    print(\"Successfully created the model directory '%s' \" % read_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476e7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_loss(output, target):\n",
    "    loss = torch.mean(torch.abs(output - target))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4428629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=L size=512x512 at 0x1C996E49F08>\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=L size=512x512 at 0x1C996EC1EC8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sli248\\Anaconda3\\envs\\unet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "C:\\Users\\sli248\\Anaconda3\\envs\\unet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "C:\\Users\\sli248\\Anaconda3\\envs\\unet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:729: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 96, 96] doesn't match the broadcast shape [3, 96, 96]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19100\\4180018026.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[0mmodel_test\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[0mk\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[1;31m#If want to get the input images with their Augmentation - To check the data flowing in net\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\unet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    679\u001B[0m                 \u001B[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    680\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 681\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    682\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    683\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\unet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    719\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    720\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 721\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    722\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    723\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory_device\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\unet\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\unet\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\ZReconstruction\\DeepLearning\\Unet-Segmentation-Pytorch-Nest-of-Unets\\Data_Loader.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, i)\u001B[0m\n\u001B[0;32m    103\u001B[0m         \u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    104\u001B[0m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmanual_seed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 105\u001B[1;33m         \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtx\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    106\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    107\u001B[0m         \u001B[1;31m# apply this seed to target/label tranfsorms\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\unet\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     92\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 94\u001B[1;33m             \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     95\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\unet\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\unet\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, tensor)\u001B[0m\n\u001B[0;32m    267\u001B[0m             \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mNormalized\u001B[0m \u001B[0mTensor\u001B[0m \u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    268\u001B[0m         \"\"\"\n\u001B[1;32m--> 269\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minplace\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    270\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    271\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\unet\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001B[0m in \u001B[0;36mnormalize\u001B[1;34m(tensor, mean, std, inplace)\u001B[0m\n\u001B[0;32m    358\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    359\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 360\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mF_t\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstd\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minplace\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    361\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    362\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\unet\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py\u001B[0m in \u001B[0;36mnormalize\u001B[1;34m(tensor, mean, std, inplace)\u001B[0m\n\u001B[0;32m    957\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mstd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    958\u001B[0m         \u001B[0mstd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 959\u001B[1;33m     \u001B[0mtensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msub_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdiv_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    960\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    961\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: output with shape [1, 96, 96] doesn't match the broadcast shape [3, 96, 96]"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#Training loop\n",
    "#######################################################\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    since = time.time()\n",
    "    scheduler.step(i)\n",
    "    lr = scheduler.get_lr()\n",
    "\n",
    "    model_test.train()\n",
    "    k = 1\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        #If want to get the input images with their Augmentation - To check the data flowing in net\n",
    "        input_images(x, y, i, n_iter, k)\n",
    "       # grid_img = torchvision.utils.make_grid(x)\n",
    "        #writer1.add_image('images', grid_img, 0)\n",
    "       # grid_lab = torchvision.utils.make_grid(y)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        y_pred = model_test(x)\n",
    "        lossT = L1_loss(y_pred, y)  # calc_loss(y_pred, y)     # Dice_loss Used\n",
    "\n",
    "        train_loss += lossT.item() * x.size(0)\n",
    "        lossT.backward()\n",
    "      #  plot_grad_flow(model_test.named_parameters(), n_iter)\n",
    "        opt.step()\n",
    "        x_size = lossT.item() * x.size(0)\n",
    "        k = 2\n",
    "\n",
    "    #    for name, param in model_test.named_parameters():\n",
    "    #        name = name.replace('.', '/')\n",
    "    #        writer1.add_histogram(name, param.data.cpu().numpy(), i + 1)\n",
    "    #        writer1.add_histogram(name + '/grad', param.grad.data.cpu().numpy(), i + 1)\n",
    "\n",
    "\n",
    "    #######################################################\n",
    "    #Validation Step\n",
    "    #######################################################\n",
    "\n",
    "    model_test.eval()\n",
    "    torch.no_grad() #to increase the validation process uses less memory\n",
    "\n",
    "    for x1, y1 in valid_loader:\n",
    "        x1, y1 = x1.to(device), y1.to(device)\n",
    "\n",
    "        y_pred1 = model_test(x1)\n",
    "        lossL = calc_loss(y_pred1, y1)     # Dice_loss Used\n",
    "\n",
    "        valid_loss += lossL.item() * x1.size(0)\n",
    "        x_size1 = lossL.item() * x1.size(0)\n",
    "\n",
    "    #######################################################\n",
    "    #Saving the predictions\n",
    "    #######################################################\n",
    "\n",
    "    im_tb = Image.open(test_image)\n",
    "    im_label = Image.open(test_label)\n",
    "    s_tb = data_transform(im_tb)\n",
    "    s_label = data_transform(im_label)\n",
    "    s_label = s_label.detach().numpy()\n",
    "\n",
    "    pred_tb = model_test(s_tb.unsqueeze(0).to(device)).cpu()\n",
    "    pred_tb = F.sigmoid(pred_tb)\n",
    "    pred_tb = pred_tb.detach().numpy()\n",
    "\n",
    "   #pred_tb = threshold_predictions_v(pred_tb)\n",
    "\n",
    "    x1 = plt.imsave(\n",
    "        './model/pred/img_iteration_' + str(n_iter) + '_epoch_'\n",
    "        + str(i) + '.png', pred_tb[0][0])\n",
    "\n",
    "  #  accuracy = accuracy_score(pred_tb[0][0], s_label)\n",
    "\n",
    "    #######################################################\n",
    "    #To write in Tensorboard\n",
    "    #######################################################\n",
    "\n",
    "    train_loss = train_loss / len(train_idx)\n",
    "    valid_loss = valid_loss / len(valid_idx)\n",
    "\n",
    "    if (i+1) % 1 == 0:\n",
    "        print('Epoch: {}/{} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(i + 1, epoch, train_loss,\n",
    "                                                                                      valid_loss))\n",
    " #       writer1.add_scalar('Train Loss', train_loss, n_iter)\n",
    "  #      writer1.add_scalar('Validation Loss', valid_loss, n_iter)\n",
    "        #writer1.add_image('Pred', pred_tb[0]) #try to get output of shape 3\n",
    "\n",
    "\n",
    "    #######################################################\n",
    "    #Early Stopping\n",
    "    #######################################################\n",
    "\n",
    "    if valid_loss <= valid_loss_min and epoch_valid >= i: # and i_valid <= 2:\n",
    "\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model '.format(valid_loss_min, valid_loss))\n",
    "        torch.save(model_test.state_dict(),'./model/Unet_D_' +\n",
    "                                              str(epoch) + '_' + str(batch_size) + '/Unet_epoch_' + str(epoch)\n",
    "                                              + '_batchsize_' + str(batch_size) + '.pth')\n",
    "       # print(accuracy)\n",
    "        if round(valid_loss, 4) == round(valid_loss_min, 4):\n",
    "            print(i_valid)\n",
    "            i_valid = i_valid+1\n",
    "        valid_loss_min = valid_loss\n",
    "        #if i_valid ==3:\n",
    "         #   break\n",
    "\n",
    "    #######################################################\n",
    "    # Extracting the intermediate layers\n",
    "    #######################################################\n",
    "\n",
    "    #####################################\n",
    "    # for kernals\n",
    "    #####################################\n",
    "    x1 = torch.nn.ModuleList(model_test.children())\n",
    "    # x2 = torch.nn.ModuleList(x1[16].children())\n",
    "     #x3 = torch.nn.ModuleList(x2[0].children())\n",
    "\n",
    "    #To get filters in the layers\n",
    "     #plot_kernels(x1.weight.detach().cpu(), 7)\n",
    "\n",
    "    #####################################\n",
    "    # for images\n",
    "    #####################################\n",
    "    x2 = len(x1)\n",
    "    dr = LayerActivations(x1[x2-1]) #Getting the last Conv Layer\n",
    "\n",
    "    img = Image.open(test_image)\n",
    "    s_tb = data_transform(img)\n",
    "\n",
    "    pred_tb = model_test(s_tb.unsqueeze(0).to(device)).cpu()\n",
    "    pred_tb = F.sigmoid(pred_tb)\n",
    "    pred_tb = pred_tb.detach().numpy()\n",
    "\n",
    "    plot_kernels(dr.features, n_iter, 7, cmap=\"rainbow\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    n_iter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#closing the tensorboard writer\n",
    "#######################################################\n",
    "\n",
    "#writer1.close()\n",
    "\n",
    "#######################################################\n",
    "#if using dict\n",
    "#######################################################\n",
    "\n",
    "#model_test.filter_dict\n",
    "\n",
    "#######################################################\n",
    "#Loading the model\n",
    "#######################################################\n",
    "\n",
    "test1 =model_test.load_state_dict(torch.load('./model/Unet_D_' +\n",
    "                   str(epoch) + '_' + str(batch_size)+ '/Unet_epoch_' + str(epoch)\n",
    "                   + '_batchsize_' + str(batch_size) + '.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#checking if cuda is available\n",
    "#######################################################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "#######################################################\n",
    "#Loading the model\n",
    "#######################################################\n",
    "\n",
    "model_test.load_state_dict(torch.load('./model/Unet_D_' +\n",
    "                   str(epoch) + '_' + str(batch_size)+ '/Unet_epoch_' + str(epoch)\n",
    "                   + '_batchsize_' + str(batch_size) + '.pth'))\n",
    "\n",
    "model_test.eval()\n",
    "\n",
    "#######################################################\n",
    "#opening the test folder and creating a folder for generated images\n",
    "#######################################################\n",
    "\n",
    "read_test_folder = glob.glob(test_folderP)\n",
    "x_sort_test = natsort.natsorted(read_test_folder)  # To sort\n",
    "\n",
    "\n",
    "read_test_folder112 = './model/gen_images'\n",
    "\n",
    "\n",
    "if os.path.exists(read_test_folder112) and os.path.isdir(read_test_folder112):\n",
    "    shutil.rmtree(read_test_folder112)\n",
    "\n",
    "try:\n",
    "    os.mkdir(read_test_folder112)\n",
    "except OSError:\n",
    "    print(\"Creation of the testing directory %s failed\" % read_test_folder112)\n",
    "else:\n",
    "    print(\"Successfully created the testing directory %s \" % read_test_folder112)\n",
    "\n",
    "\n",
    "#For Prediction Threshold\n",
    "\n",
    "read_test_folder_P_Thres = './model/pred_threshold'\n",
    "\n",
    "\n",
    "if os.path.exists(read_test_folder_P_Thres) and os.path.isdir(read_test_folder_P_Thres):\n",
    "    shutil.rmtree(read_test_folder_P_Thres)\n",
    "\n",
    "try:\n",
    "    os.mkdir(read_test_folder_P_Thres)\n",
    "except OSError:\n",
    "    print(\"Creation of the testing directory %s failed\" % read_test_folder_P_Thres)\n",
    "else:\n",
    "    print(\"Successfully created the testing directory %s \" % read_test_folder_P_Thres)\n",
    "\n",
    "#For Label Threshold\n",
    "\n",
    "read_test_folder_L_Thres = './model/label_threshold'\n",
    "\n",
    "\n",
    "if os.path.exists(read_test_folder_L_Thres) and os.path.isdir(read_test_folder_L_Thres):\n",
    "    shutil.rmtree(read_test_folder_L_Thres)\n",
    "\n",
    "try:\n",
    "    os.mkdir(read_test_folder_L_Thres)\n",
    "except OSError:\n",
    "    print(\"Creation of the testing directory %s failed\" % read_test_folder_L_Thres)\n",
    "else:\n",
    "    print(\"Successfully created the testing directory %s \" % read_test_folder_L_Thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf65ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#saving the images in the files\n",
    "#######################################################\n",
    "\n",
    "img_test_no = 0\n",
    "\n",
    "for i in range(len(read_test_folder)):\n",
    "    im = Image.open(x_sort_test[i])\n",
    "\n",
    "    im1 = im\n",
    "    im_n = np.array(im1)\n",
    "    im_n_flat = im_n.reshape(-1, 1)\n",
    "\n",
    "    for j in range(im_n_flat.shape[0]):\n",
    "        if im_n_flat[j] != 0:\n",
    "            im_n_flat[j] = 255\n",
    "\n",
    "    s = data_transform(im)\n",
    "    pred = model_test(s.unsqueeze(0).cuda()).cpu()\n",
    "    pred = F.sigmoid(pred)\n",
    "    pred = pred.detach().numpy()\n",
    "\n",
    "#    pred = threshold_predictions_p(pred) #Value kept 0.01 as max is 1 and noise is very small.\n",
    "\n",
    "    if i % 24 == 0:\n",
    "        img_test_no = img_test_no + 1\n",
    "\n",
    "    x1 = plt.imsave('./model/gen_images/im_epoch_' + str(epoch) + 'int_' + str(i)\n",
    "                    + '_img_no_' + str(img_test_no) + '.png', pred[0][0])\n",
    "\n",
    "\n",
    "####################################################\n",
    "#Calculating the Dice Score\n",
    "####################################################\n",
    "\n",
    "data_transform = torchvision.transforms.Compose([\n",
    "          #  torchvision.transforms.Resize((128,128)),\n",
    "        #    torchvision.transforms.CenterCrop(96),\n",
    "             torchvision.transforms.Grayscale(),\n",
    "#            torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "read_test_folderP = glob.glob('./model/gen_images/*')\n",
    "x_sort_testP = natsort.natsorted(read_test_folderP)\n",
    "\n",
    "\n",
    "read_test_folderL = glob.glob(test_folderL)\n",
    "x_sort_testL = natsort.natsorted(read_test_folderL)  # To sort\n",
    "\n",
    "\n",
    "dice_score123 = 0.0\n",
    "x_count = 0\n",
    "x_dice = 0\n",
    "\n",
    "for i in range(len(read_test_folderP)):\n",
    "\n",
    "    x = Image.open(x_sort_testP[i])\n",
    "    s = data_transform(x)\n",
    "    s = np.array(s)\n",
    "    s = threshold_predictions_v(s)\n",
    "\n",
    "    #save the images\n",
    "    x1 = plt.imsave('./model/pred_threshold/im_epoch_' + str(epoch) + 'int_' + str(i)\n",
    "                    + '_img_no_' + str(img_test_no) + '.png', s)\n",
    "\n",
    "    y = Image.open(x_sort_testL[i])\n",
    "    s2 = data_transform(y)\n",
    "    s3 = np.array(s2)\n",
    "   # s2 =threshold_predictions_v(s2)\n",
    "\n",
    "    #save the Images\n",
    "    y1 = plt.imsave('./model/label_threshold/im_epoch_' + str(epoch) + 'int_' + str(i)\n",
    "                    + '_img_no_' + str(img_test_no) + '.png', s3)\n",
    "\n",
    "    total = dice_coeff(s, s3)\n",
    "    print(total)\n",
    "\n",
    "    if total <= 0.3:\n",
    "        x_count += 1\n",
    "    if total > 0.3:\n",
    "        x_dice = x_dice + total\n",
    "    dice_score123 = dice_score123 + total\n",
    "\n",
    "\n",
    "print('Dice Score : ' + str(dice_score123/len(read_test_folderP)))\n",
    "#print(x_count)\n",
    "#print(x_dice)\n",
    "#print('Dice Score : ' + str(float(x_dice/(len(read_test_folderP)-x_count))))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
