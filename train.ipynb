{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "#import SimpleITK as sitk\n",
    "from torch import optim\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import natsort\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from Data_Loader import Images_Dataset_folder\n",
    "import torchsummary\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#from tensorboardX import SummaryWriter\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "from Models import Unet_dict, NestedUNet, U_Net, R2U_Net, AttU_Net, R2AttU_Net,U_Net_Perceptual,SCUNet\n",
    "from Transformer_UNet import Transformer_U_Net\n",
    "from TUNet import U_Transformer\n",
    "from losses import calc_loss, dice_loss, threshold_predictions_v,threshold_predictions_p\n",
    "from ploting import plot_kernels, LayerActivations, input_images, plot_grad_flow\n",
    "from Metrics import dice_coeff, accuracy_score\n",
    "import time\n",
    "import pdb\n",
    "#from ploting import VisdomLinePlotter\n",
    "#from visdom import Visdom\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Training on GPU\n",
      "batch_size = 32\n",
      "epoch = 600\n",
      "random_seed = 55\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─MaxPool2d: 1-1                         --\n",
      "├─MaxPool2d: 1-2                         --\n",
      "├─MaxPool2d: 1-3                         --\n",
      "├─MaxPool2d: 1-4                         --\n",
      "├─conv_block: 1-5                        --\n",
      "|    └─Sequential: 2-1                   --\n",
      "|    |    └─Conv2d: 3-1                  1,792\n",
      "|    |    └─BatchNorm2d: 3-2             128\n",
      "|    |    └─ReLU: 3-3                    --\n",
      "|    |    └─Conv2d: 3-4                  36,928\n",
      "|    |    └─BatchNorm2d: 3-5             128\n",
      "|    |    └─ReLU: 3-6                    --\n",
      "├─conv_block: 1-6                        --\n",
      "|    └─Sequential: 2-2                   --\n",
      "|    |    └─Conv2d: 3-7                  73,856\n",
      "|    |    └─BatchNorm2d: 3-8             256\n",
      "|    |    └─ReLU: 3-9                    --\n",
      "|    |    └─Conv2d: 3-10                 147,584\n",
      "|    |    └─BatchNorm2d: 3-11            256\n",
      "|    |    └─ReLU: 3-12                   --\n",
      "├─conv_block: 1-7                        --\n",
      "|    └─Sequential: 2-3                   --\n",
      "|    |    └─Conv2d: 3-13                 295,168\n",
      "|    |    └─BatchNorm2d: 3-14            512\n",
      "|    |    └─ReLU: 3-15                   --\n",
      "|    |    └─Conv2d: 3-16                 590,080\n",
      "|    |    └─BatchNorm2d: 3-17            512\n",
      "|    |    └─ReLU: 3-18                   --\n",
      "├─conv_block: 1-8                        --\n",
      "|    └─Sequential: 2-4                   --\n",
      "|    |    └─Conv2d: 3-19                 1,180,160\n",
      "|    |    └─BatchNorm2d: 3-20            1,024\n",
      "|    |    └─ReLU: 3-21                   --\n",
      "|    |    └─Conv2d: 3-22                 2,359,808\n",
      "|    |    └─BatchNorm2d: 3-23            1,024\n",
      "|    |    └─ReLU: 3-24                   --\n",
      "├─conv_block: 1-9                        --\n",
      "|    └─Sequential: 2-5                   --\n",
      "|    |    └─Conv2d: 3-25                 4,719,616\n",
      "|    |    └─BatchNorm2d: 3-26            2,048\n",
      "|    |    └─ReLU: 3-27                   --\n",
      "|    |    └─Conv2d: 3-28                 9,438,208\n",
      "|    |    └─BatchNorm2d: 3-29            2,048\n",
      "|    |    └─ReLU: 3-30                   --\n",
      "├─up_conv: 1-10                          --\n",
      "|    └─Sequential: 2-6                   --\n",
      "|    |    └─Upsample: 3-31               --\n",
      "|    |    └─Conv2d: 3-32                 4,719,104\n",
      "|    |    └─BatchNorm2d: 3-33            1,024\n",
      "|    |    └─ReLU: 3-34                   --\n",
      "├─conv_block: 1-11                       --\n",
      "|    └─Sequential: 2-7                   --\n",
      "|    |    └─Conv2d: 3-35                 4,719,104\n",
      "|    |    └─BatchNorm2d: 3-36            1,024\n",
      "|    |    └─ReLU: 3-37                   --\n",
      "|    |    └─Conv2d: 3-38                 2,359,808\n",
      "|    |    └─BatchNorm2d: 3-39            1,024\n",
      "|    |    └─ReLU: 3-40                   --\n",
      "├─up_conv: 1-12                          --\n",
      "|    └─Sequential: 2-8                   --\n",
      "|    |    └─Upsample: 3-41               --\n",
      "|    |    └─Conv2d: 3-42                 1,179,904\n",
      "|    |    └─BatchNorm2d: 3-43            512\n",
      "|    |    └─ReLU: 3-44                   --\n",
      "├─conv_block: 1-13                       --\n",
      "|    └─Sequential: 2-9                   --\n",
      "|    |    └─Conv2d: 3-45                 1,179,904\n",
      "|    |    └─BatchNorm2d: 3-46            512\n",
      "|    |    └─ReLU: 3-47                   --\n",
      "|    |    └─Conv2d: 3-48                 590,080\n",
      "|    |    └─BatchNorm2d: 3-49            512\n",
      "|    |    └─ReLU: 3-50                   --\n",
      "├─up_conv: 1-14                          --\n",
      "|    └─Sequential: 2-10                  --\n",
      "|    |    └─Upsample: 3-51               --\n",
      "|    |    └─Conv2d: 3-52                 295,040\n",
      "|    |    └─BatchNorm2d: 3-53            256\n",
      "|    |    └─ReLU: 3-54                   --\n",
      "├─conv_block: 1-15                       --\n",
      "|    └─Sequential: 2-11                  --\n",
      "|    |    └─Conv2d: 3-55                 295,040\n",
      "|    |    └─BatchNorm2d: 3-56            256\n",
      "|    |    └─ReLU: 3-57                   --\n",
      "|    |    └─Conv2d: 3-58                 147,584\n",
      "|    |    └─BatchNorm2d: 3-59            256\n",
      "|    |    └─ReLU: 3-60                   --\n",
      "├─up_conv: 1-16                          --\n",
      "|    └─Sequential: 2-12                  --\n",
      "|    |    └─Upsample: 3-61               --\n",
      "|    |    └─Conv2d: 3-62                 73,792\n",
      "|    |    └─BatchNorm2d: 3-63            128\n",
      "|    |    └─ReLU: 3-64                   --\n",
      "├─conv_block: 1-17                       --\n",
      "|    └─Sequential: 2-13                  --\n",
      "|    |    └─Conv2d: 3-65                 73,792\n",
      "|    |    └─BatchNorm2d: 3-66            128\n",
      "|    |    └─ReLU: 3-67                   --\n",
      "|    |    └─Conv2d: 3-68                 36,928\n",
      "|    |    └─BatchNorm2d: 3-69            128\n",
      "|    |    └─ReLU: 3-70                   --\n",
      "├─Conv2d: 1-18                           195\n",
      "├─Sigmoid: 1-19                          --\n",
      "=================================================================\n",
      "Total params: 34,527,171\n",
      "Trainable params: 34,527,171\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available. Training on CPU')\n",
    "else:\n",
    "    print('CUDA is available. Training on GPU')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "print('batch_size = ' + str(batch_size))\n",
    "\n",
    "valid_size = 0.15\n",
    "\n",
    "epoch = 600\n",
    "print('epoch = ' + str(epoch))\n",
    "\n",
    "random_seed = random.randint(1, 100)\n",
    "print('random_seed = ' + str(random_seed))\n",
    "\n",
    "shuffle = True\n",
    "valid_loss_min = np.Inf\n",
    "num_workers = 0\n",
    "lossT = []\n",
    "lossL = []\n",
    "lossL.append(np.inf)\n",
    "lossT.append(np.inf)\n",
    "epoch_valid = epoch-2\n",
    "n_iter = 1\n",
    "i_valid = 0\n",
    "\n",
    "\"\"\"\n",
    "You also need to change the width and height in the Data_loader.py!!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "pin_memory = False\n",
    "if train_on_gpu:\n",
    "    pin_memory = True\n",
    "\n",
    "\n",
    "model_Inputs = [U_Net, R2U_Net, AttU_Net, R2AttU_Net, NestedUNet]\n",
    "\n",
    "\n",
    "def model_unet(model_input, in_channel=3, out_channel=1):\n",
    "    model_test = model_input(in_channel, out_channel)\n",
    "    return model_test\n",
    "\n",
    "\n",
    "model_test = model_unet(U_Net, 3, 3)\n",
    "\n",
    "DATE = \"20230331\"\n",
    "\n",
    "t_data = \"C:/Users/sli248/ZReconstruction/DL/dataset/train/input/\"\n",
    "l_data = \"C:/Users/sli248/ZReconstruction/DL/dataset/train/label/\"\n",
    "test_image = \"C:/Users/sli248/ZReconstruction/DL/dataset/test/input/BSDS100_38092.png\"\n",
    "test_label = \"C:/Users/sli248/ZReconstruction/DL/dataset/test/label/BSDS100_38092.png\"\n",
    "test_folderP = \"C:/Users/sli248/ZReconstruction/DL/dataset/test/input/*\"\n",
    "test_folderL = \"C:/Users/sli248/ZReconstruction/DL/dataset/test/label/*\"\n",
    "\n",
    "InputW = 128\n",
    "InputH = 128\n",
    "\n",
    "model_test.to(device)\n",
    "torchsummary.summary(model_test, input_size=(3, InputW, InputH))\n",
    "\n",
    "def self_transforms(inputW, inputH):\n",
    "    if inputW == 0:\n",
    "        return torchvision.transforms.Compose([\n",
    "                torchvision.transforms.ToTensor()\n",
    "            ])\n",
    "    else:\n",
    "        return torchvision.transforms.Compose([\n",
    "                torchvision.transforms.CenterCrop(128),\n",
    "                torchvision.transforms.Resize((inputW, inputH)),\n",
    "                torchvision.transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "train_transform = self_transforms(InputW, InputH)\n",
    "test_transform = self_transforms(0, 0)\n",
    "\n",
    "\n",
    "Training_Data = Images_Dataset_folder(t_data,\n",
    "                                      l_data,\n",
    "                                      train_transform,\n",
    "                                      train_transform)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#Trainging Validation Split\n",
    "#######################################################\n",
    "\n",
    "num_train = len(Training_Data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "if shuffle:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "print(len(train_idx), len(valid_idx))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(Training_Data, batch_size=batch_size, sampler=train_sampler,\n",
    "                                           num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(Training_Data, batch_size=batch_size, sampler=valid_sampler,\n",
    "                                           num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "\n",
    "# for x, y in train_loader:\n",
    "#     x, y = x.to(device), y.to(device)\n",
    "#     print(\"X = \",x.min(),x.max())\n",
    "#     print(\"Y = \",y.min(),y.max())\n",
    "\n",
    "\n",
    "######################################################\n",
    "#Using Adam as Optimizer\n",
    "#######################################################\n",
    "\n",
    "initial_lr = 1e-3\n",
    "opt = torch.optim.Adam(model_test.parameters(), lr=initial_lr) # try SGD weight_decay=0.1\n",
    "#opt = optim.SGD(model_test.parameters(), lr = initial_lr, momentum=0.99)\n",
    "\n",
    "MAX_STEP = int(1e10)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, MAX_STEP, eta_min=1e-5)\n",
    "#scheduler = optim.lr_scheduler.CosineAnnealingLr(opt, epoch, 1)\n",
    "\n",
    "#######################################################\n",
    "#Writing the params to tensorboard\n",
    "#######################################################\n",
    "\n",
    "#writer1 = SummaryWriter()\n",
    "#dummy_inp = torch.randn(1, 3, 128, 128)\n",
    "#model_test.to('cpu')\n",
    "#writer1.add_graph(model_test, model_test(torch.randn(3, 3, 128, 128, requires_grad=True)))\n",
    "#model_test.to(device)\n",
    "\n",
    "#######################################################\n",
    "#Creating a Folder for every data of the program\n",
    "#######################################################\n",
    "\n",
    "New_folder = './model'\n",
    "\n",
    "if os.path.exists(New_folder) and os.path.isdir(New_folder):\n",
    "    shutil.rmtree(New_folder)\n",
    "\n",
    "try:\n",
    "    os.mkdir(New_folder)\n",
    "except OSError:\n",
    "    print(\"Creation of the main directory '%s' failed \" % New_folder)\n",
    "else:\n",
    "    print(\"Successfully created the main directory '%s' \" % New_folder)\n",
    "\n",
    "#######################################################\n",
    "#Setting the folder of saving the predictions\n",
    "#######################################################\n",
    "\n",
    "read_pred = os.path.join(New_folder,'pred')\n",
    "\n",
    "#######################################################\n",
    "#Checking if prediction folder exixts\n",
    "#######################################################\n",
    "\n",
    "if os.path.exists(read_pred) and os.path.isdir(read_pred):\n",
    "    shutil.rmtree(read_pred)\n",
    "\n",
    "try:\n",
    "    os.mkdir(read_pred)\n",
    "except OSError:\n",
    "    print(\"Creation of the prediction directory '%s' failed of dice loss\" % read_pred)\n",
    "else:\n",
    "    print(\"Successfully created the prediction directory '%s' of dice loss\" % read_pred)\n",
    "\n",
    "#######################################################\n",
    "#checking if the model exists and if true then delete\n",
    "#######################################################\n",
    "\n",
    "model_state_folder = 'UNet_D_' + str(epoch) + '_' + str(batch_size)\n",
    "read_model_path = os.path.join(New_folder,model_state_folder)\n",
    "\n",
    "if os.path.exists(read_model_path) and os.path.isdir(read_model_path):\n",
    "    shutil.rmtree(read_model_path)\n",
    "    print('Model folder there, so deleted for newer one')\n",
    "\n",
    "try:\n",
    "    os.mkdir(read_model_path)\n",
    "except OSError:\n",
    "    print(\"Creation of the model directory '%s' failed\" % read_model_path)\n",
    "else:\n",
    "    print(\"Successfully created the model directory '%s' \" % read_model_path)\n",
    "\n",
    "#######################################################\n",
    "#Training loop\n",
    "#######################################################\n",
    "\n",
    "def L1_loss(output, target):\n",
    "    loss = torch.mean(torch.abs(output - target))\n",
    "    return loss\n",
    "def L2_loss(output, target):\n",
    "    loss = torch.mean(torch.square(output - target))\n",
    "    return loss\n",
    "\n",
    "#def perceptual_loss(output, target):\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calc_loss = torch.nn.MSELoss() #L2_loss\n",
    "# calc_loss = torch.nn.L1Loss()\n",
    "for i in range(epoch):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    since = time.time()\n",
    "\n",
    "    lr = scheduler.get_last_lr() #get_lr()\n",
    "    #######################################################\n",
    "    #Training Data\n",
    "    #######################################################\n",
    "    model_test.train()\n",
    "    k = 1\n",
    "    for x, y in tqdm(train_loader,position=0,leave=True):\n",
    "        # print(x.shape,y.shape)\n",
    "        # print(x.size(), y.size())\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "\n",
    "        # ====== Perceptual Loss ======\n",
    "        y_pred = model_test(x)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        loss =  calc_loss(y_pred, y)\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    #######################################################\n",
    "    #Validation Step\n",
    "    #######################################################\n",
    "\n",
    "    model_test.eval()\n",
    "    torch.no_grad() #to increase the validation process uses less memory\n",
    "\n",
    "    for x1, y1 in tqdm(valid_loader,position=0,leave=True):\n",
    "        x1, y1 = x1.to(device), y1.to(device) #[batch_size, channel, w, h]\n",
    "\n",
    "        y_pred1 = model_test(x1)\n",
    "        loss = calc_loss(y_pred1, y1)     # Dice_loss Used\n",
    "\n",
    "        valid_loss += loss.item() * x1.size(0)\n",
    "\n",
    "    #######################################################\n",
    "    #Saving the predictions\n",
    "    #######################################################\n",
    "\n",
    "    im_tb = Image.open(test_image)\n",
    "    im_label = Image.open(test_label)\n",
    "    s_tb = test_transform(im_tb)\n",
    "    s_label = test_transform(im_label)\n",
    "    s_label = s_label.detach().numpy()\n",
    "    #pred_tb = model_test(s_tb.unsqueeze(0).to(device)).cpu()\n",
    "    pred_tb = model_test(s_tb.unsqueeze(0).to(device)).cpu() #model_test().cpu()\n",
    "    #pred_tb = torch.sigmoid(pred_tb)\n",
    "    pred_tb = pred_tb.detach().numpy()#[0]#.transpose(2, 0, 1)\n",
    "    #pdb.set_trace()\n",
    "   #pred_tb = threshold_predictions_v(pred_tb)\n",
    "    fig = plt.figure()\n",
    "    plt.imsave(\n",
    "        './model/pred/img_iteration_' + str(n_iter) + '_epoch_'\n",
    "        + str(i) + '.png', pred_tb[0].transpose(1, 2, 0))\n",
    "    plt.close(fig)\n",
    "  #  accuracy = accuracy_score(pred_tb[0][0], s_label)\n",
    "\n",
    "    train_loss = train_loss #/ len(train_idx)\n",
    "    valid_loss = valid_loss #/ len(valid_idx)\n",
    "    lossT.append(train_loss)\n",
    "    lossL.append(valid_loss)\n",
    "    if (i+1) % 1 == 0:\n",
    "        print('Epoch: {}/{} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(i + 1, epoch, train_loss,\n",
    "                                                                                      valid_loss))\n",
    "    if (i+1) % 10  == 0:\n",
    "        savelossT = np.array(lossT)\n",
    "        savelossL = np.array(lossL)\n",
    "        np.save(\"./model/train_loss.npy\",savelossT)\n",
    "        np.save(\"./model/valid_loss.npy\",savelossL)\n",
    "        torch.save(model_test.state_dict(), os.path.join(read_model_path, 'Unet_epoch_' + str(i) + '_batchsize_' + str(batch_size) + '.pth'))\n",
    "\n",
    "    #######################################################\n",
    "    #Early Stopping\n",
    "    #######################################################\n",
    "\n",
    "    #######################################################\n",
    "    # Extracting the intermediate layers\n",
    "    #######################################################\n",
    "\n",
    "    #####################################\n",
    "    # for kernals\n",
    "    #####################################\n",
    "    x1 = torch.nn.ModuleList(model_test.children())\n",
    "    # x2 = torch.nn.ModuleList(x1[16].children())\n",
    "     #x3 = torch.nn.ModuleList(x2[0].children())\n",
    "\n",
    "    #To get filters in the layers\n",
    "     #plot_kernels(x1.weight.detach().cpu(), 7)\n",
    "\n",
    "    #####################################\n",
    "    # for images\n",
    "    #####################################\n",
    "    x2 = len(x1)\n",
    "    dr = LayerActivations(x1[x2-1]) #Getting the last Conv Layer\n",
    "\n",
    "    img = Image.open(test_image)\n",
    "    s_tb = test_transform(img)\n",
    "\n",
    "    pred_tb = model_test(s_tb.unsqueeze(0).to(device))[0].cpu()\n",
    "    #pred_tb = torch.sigmoid(pred_tb)\n",
    "    pred_tb = pred_tb.detach().numpy()\n",
    "\n",
    "    #plot_kernels(dr.features, n_iter, 7, cmap=\"rainbow\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    n_iter += 1\n",
    "\n",
    "    if valid_loss <= valid_loss_min:# and epoch_valid >= i: # and i_valid <= 2:\n",
    "\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model '.format(valid_loss_min, valid_loss))\n",
    "        torch.save(model_test.state_dict(),os.path.join(read_model_path, 'best.pth'))\n",
    "       # print(accuracy)\n",
    "       #  if round(valid_loss, 4) == round(valid_loss_min, 4):\n",
    "       #      print(i_valid)\n",
    "       #      i_valid = i_valid+1\n",
    "        i_valid = 0\n",
    "        valid_loss_min = valid_loss\n",
    "    else:\n",
    "        i_valid += 1\n",
    "        if i_valid > 100:\n",
    "            print(\"due to the loss is not decreasing from last 50 epochs, the model stop training\")\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
